# VidScalerSubtitleAdder - Claude Development Guide

## ProjektÃ¼bersicht
GUI-Anwendung zum Skalieren von Videos mit FFmpeg unter Windows 11.
**âœ… Phase 1 implementiert:** Untertitel-EinfÃ¼gung funktioniert perfekt!

## Technische Anforderungen
- Python 3.7+ mit tkinter (standard)
- FFmpeg im System PATH
- Windows 11 kompatibel

## Setup Commands

### Virtuelle Umgebung erstellen und aktivieren (Windows):
```bash
python -m venv .venv
.venv\Scripts\activate
```

### Dependencies installieren:
```bash
pip install -r requirements.txt
```

### Anwendung starten:
```bash
python vidscaler.py
```

## Windows Batch Starter

**WICHTIG**: Das Projekt hat eine `start.bat` fÃ¼r einfachen Doppelklick-Start!
- âœ… Automatische Virtual Environment Aktivierung
- âœ… Startet `python vidscaler.py`
- âœ… Konsole bleibt offen fÃ¼r Fehlerausgaben

## Projektstruktur
```
VidScaler/
â”œâ”€â”€ vidscaler.py          # Haupt-GUI-Anwendung
â”œâ”€â”€ video_processor.py    # FFmpeg-Interface
â”œâ”€â”€ utils.py             # Hilfsfunktionen
â”œâ”€â”€ audio_transcriber.py  # Audio-zu-SRT Transkriptor mit Whisper
â”œâ”€â”€ translator.py        # SRT-Ãœbersetzungs-Engine
â”œâ”€â”€ requirements.txt     # AbhÃ¤ngigkeiten
â”œâ”€â”€ start.bat            # Windows Doppelklick-Starter
â”œâ”€â”€ .venv/              # Virtual Environment
â”œâ”€â”€ README.md           # Benutzeranleitung
â””â”€â”€ CLAUDE.md          # Diese Datei
```

## Entwicklungsrichtlinien
- **Einfachheit**: Minimale AbhÃ¤ngigkeiten, tkinter-Standard
- **Windows-First**: Pfade mit os.path, Windows-Pfad-Handling
- **Error Handling**: Robuste FFmpeg-Fehlerbehandlung
- **Type Hints**: FÃ¼r bessere Code-QualitÃ¤t
- **Logging**: FÃ¼r Debugging und Benutzer-Feedback

## Core Features
1. **File Selection**: Einfache Videodatei-Auswahl
2. **Resolution Display**: Aktuelle Video-Dimensionen anzeigen
3. **Smart Scaling**: Dropdown mit geraden Pixel-Werten
4. **FFmpeg Integration**: subprocess-basierte Videoverarbeitung
5. **Progress Feedback**: Status-Updates fÃ¼r Benutzer
6. **âœ… Subtitle Integration**: .srt-Dateien unterhalb des Videos einbrennen
7. **âœ… Audio Transcription**: Video â†’ Audio â†’ Text â†’ SRT mit Whisper
8. **ðŸ†• Translation Engine**: SRT-Ãœbersetzung mit mehreren Sprachen
9. **ðŸ†• Dual Subtitles**: Original oben, Ãœbersetzung unten im Video

## FFmpeg Integration
**Normale Skalierung:**
- Befehl: `ffmpeg -i input.mp4 -vf scale=WIDTH:-1 output_scaled.mp4`
- Gerade Pixelwerte (durch 2 teilbar) fÃ¼r KompatibilitÃ¤t
- Proportionale Skalierung mit -1 fÃ¼r HÃ¶he

**âœ… Untertitel-Integration (funktioniert perfekt):**
- Befehl: `ffmpeg -i input.mp4 -vf "scale=WIDTH:-2,pad=iw:ih+100:0:0:black,subtitles=temp_subtitles.srt" output_subtitled.mp4`
- TemporÃ¤re Datei-Kopie lÃ¶st Windows-Pfad-Probleme
- Video wird um 100px nach unten erweitert
- Optimale SchriftgrÃ¶ÃŸe und Lesbarkeit

**ðŸŽ¯ Doppelte Untertitel-Integration (SRT â†’ ASS Pipeline):**
- **SRT â†’ ASS Konvertierung**: `ffmpeg -sub_charenc UTF-8 -i input.srt output.ass` fÃ¼r Style-Kontrolle
- **Asymmetrisches Padding**: 140px oben + 160px unten fÃ¼r optimale 2-Zeilen-Darstellung
- **PrÃ¤zise Style-Parameter**: FontSize=15, Outline=2, MarginL/R=2, WrapStyle=3
- **Positioning**: Original TopCenter (Alignment=8), Ãœbersetzung BottomCenter (Alignment=2)
- **Windows-Pfad-Fix**: TemporÃ¤re Dateien im cwd, `os.path.basename()` in FFmpeg-Filtern
- **Befehl**: `ffmpeg -i input.mp4 -vf "scale=WIDTH:-2,pad=iw:ih+300:0:140:black,ass=original.ass,ass=translated.ass" output.mp4`

## Testing Approach
- Manuelle Tests mit verschiedenen Video-Formaten
- FFmpeg-VerfÃ¼gbarkeit prÃ¼fen
- Windows-Pfad-KompatibilitÃ¤t testen

## Deployment
- Standalone Python-Script
- Optional: PyInstaller fÃ¼r .exe-Distribution

## âœ… Aktueller Status (Phase 2 ERFOLGREICH getestet!)
- **Basis-Skalierung**: âœ… Funktioniert perfekt
- **Untertitel-EinfÃ¼gung**: âœ… Funktioniert perfekt - SchriftgrÃ¶ÃŸe optimal!
- **GUI**: âœ… Alle Controls implementiert und funktionsfÃ¤hig
- **Windows-KompatibilitÃ¤t**: âœ… Pfad-Probleme gelÃ¶st
- **ðŸŽ‰ Audio-Transkription**: âœ… LIVE GETESTET - funktioniert perfekt!

## ðŸ†• Phase 2 Features (Audio Transcription) - âœ… LIVE GETESTET!
- **âœ… Audio Extraction**: FFmpeg extrahiert Audio aus Video (16kHz WAV)
- **âœ… Whisper Integration**: OpenAI Whisper fÃ¼r prÃ¤zise Spracherkennung - FUNKTIONIERT!
- **âœ… Multi-Language**: Deutsch, Englisch, Auto-Erkennung
- **âœ… Model Selection**: Tiny/Base/Small - Geschwindigkeit vs. Genauigkeit
- **âœ… Segment Editor**: Timeline-basierte Text-Bearbeitung - BENUTZERFREUNDLICH!
- **âœ… SRT Export**: Direkter Export zurÃ¼ck zur Haupt-App
- **âœ… Seamless Integration**: "Audio transkribieren" Button in Haupt-GUI - PERFEKT!

## Installation (Alle Dependencies)
```bash
pip install openai-whisper matplotlib pydub translators smart-srt-translator
```

## ðŸŽ‰ Phase 3 Features (Ãœbersetzung) - âœ… PRODUKTIONSREIF!
- **âœ… Ãœbersetzungs-API**: `translators` library mit Google Translate Backend
- **âœ… SRT â†’ ASS Pipeline**: Robuste Konvertierung mit Style-Kontrolle
- **âœ… Doppelte Untertitel**: Original oben, Ãœbersetzung unten im Video
- **âœ… Sprachauswahl**: Dropdowns fÃ¼r Quell- und Zielsprache (9 Sprachen)
- **âœ… Ãœbersetzungsmodi**: "Original + Ãœbersetzung" oder "Nur Ãœbersetzung"
- **âœ… GUI Integration**: Ãœbersetzungs-Sektion mit Aktivierungs-Checkbox
- **âœ… Multi-Threading**: Ãœbersetzung und Video-Verarbeitung in separaten Threads
- **ðŸŽ¯ Windows-Pfad-Fixes**: Alle FFmpeg-Pfadprobleme gelÃ¶st durch cwd-TemporÃ¤rdateien

## ðŸš€ Phase 4 Features (Bidirektionale Whisper-Ãœbersetzung) - âœ… IMPLEMENTIERT!
- **âœ… WhisperTranslator-Klasse**: Audio-Extraktion + Whisper-Transkription in Zielsprache
- **âœ… Smart Timing-Mapping**: Whisper-Segmente auf Original-SRT-Timing gemappt
- **âœ… Triple Translation Methods**: OpenAI (beste QualitÃ¤t) vs Google Translate (schnell) vs Whisper (English-only)
- **âœ… GUI Method-Selection**: Dropdown mit dynamischen Whisper-Model-Optionen
- **âœ… Model Caching**: Whisper-Modelle werden wiederverwendet fÃ¼r Performance
- **âœ… Robustes Cleanup**: Automatische Bereinigung aller temporÃ¤ren Audio-Dateien
- **ðŸ”„ QualitÃ¤ts-Test**: Whisper-Ãœbersetzung braucht noch Feintuning/manuelle Nachbearbeitung

## ðŸ”„ Workflow (Phase 4)
1. **Video auswÃ¤hlen** â†’ Analysieren
2. **Audio transkribieren** â†’ SRT wird automatisch gesetzt 
3. **Ãœbersetzung aktivieren** â†’ Sprachen + **Methode** wÃ¤hlen â†’ Modus wÃ¤hlen
4. **"Mit Ãœbersetzung skalieren"** â†’ Fertig!

## ðŸŽ‰ Phase 5 Features (Production Quality & UX) - âœ… FERTIG!
- **âœ… Smart-SRT-Translator Integration**: Lokales `smart_translation.py` durch PyPI-Modul ersetzt
- **âœ… Optimierte GUI-Defaults**: FenstergrÃ¶ÃŸe, Audio-Transkription (Base+English), Ãœbersetzung (OpenAI+EN-Source)
- **âœ… Benutzerfreundlichkeit**: Alle Standard-Einstellungen auf hÃ¤ufigste Use-Cases optimiert
- **âœ… Modular Architecture**: Externe Dependencies Ã¼ber offizielle Package-Manager

## ðŸ“‹ Phase 6 Roadmap (Future)
- **ðŸŽ¯ Translation Editor**: GUI-Fenster zum manuellen Korrigieren von Ãœbersetzungen
- **ðŸ“ Segment-by-Segment Editing**: Wie AudioTranscriber, aber fÃ¼r Ã¼bersetzte Texte
- **ðŸ”„ Export-Integration**: Korrigierte Ãœbersetzung direkt in Video-Pipeline
- **âš¡ Whisper-Tuning**: Bessere Prompt-Engineering fÃ¼r ÃœbersetzungsqualitÃ¤t

## ðŸ› ï¸ Technische Implementierung (Phase 3 LÃ¶sung)

### FFmpeg Windows-Pfad Problematik
**Problem:** Windows-Pfade mit Laufwerksbuchstaben (`C:\path`) verursachen Parsing-Fehler in FFmpeg-Filtern
**LÃ¶sung:** TemporÃ¤re Dateien im aktuellen Arbeitsverzeichnis + `os.path.basename()` fÃ¼r Filter

### SRT â†’ ASS Konvertierungs-Pipeline
```python
def _convert_srt_to_ass(src_srt: str, dst_ass: str):
    subprocess.run([ffmpeg, "-sub_charenc", "UTF-8", "-i", src_srt, dst_ass])

def _tweak_ass_style(ass_path: str, *, alignment: int, margin_v: int, 
                     font_size: int = 15, outline: int = 2):
    # ASS V4+ Format Style-Zeile modifizieren
    # Felder: Fontsize(2), Outline(16), Shadow(17), Alignment(18), MarginV(21)
```

### Optimierte Style-Parameter
- **FontSize**: 15 (vorher 20) - kompakter fÃ¼r Dual-Mode
- **Margins**: L=2, R=2 (vorher 10/10) - mehr Platz fÃ¼r Text
- **WrapStyle**: 3 - gleichmÃ¤ÃŸigere TextumbrÃ¼che
- **Alignment**: TopCenter(8) vs BottomCenter(2)

### Video-Filter-Chain
```bash
ffmpeg -i video.mp4 -vf "
  scale=WIDTH:-2,
  pad=iw:ih+300:0:140:black,
  ass=filename=original.ass,
  ass=filename=translated.ass
" output.mp4
```

### Robustes Cleanup
```python
finally:
    for p in [temp_original_srt, temp_translated_srt, temp_original_ass, temp_translated_ass]:
        if p and os.path.exists(p):
            try: os.remove(p)
            except: pass
```

## ðŸ› ï¸ Phase 4 Technische Implementierung (Whisper-Ãœbersetzung)

### WhisperTranslator-Architektur
```python
class WhisperTranslator:
    def translate_via_whisper(self, video_path, original_srt_path, target_lang, model_size):
        # 1. Audio extrahieren (16kHz WAV fÃ¼r Whisper)
        # 2. Whisper-Modell laden + cachen
        # 3. Original-SRT-Timing als Referenz parsen
        # 4. Whisper in Zielsprache transkribieren
        # 5. Smart Timing-Mapping auf Original-Segmente
        # 6. Ãœbersetzte SRT erstellen + cleanup
```

### Smart Timing-Mapping Algorithm
```python
def _map_whisper_to_original_timing(whisper_segments, original_segments):
    # Overlap-Detection: Whisper-Segment âˆ© Original-Segment
    # Kombiniert alle Ã¼berlappenden Whisper-Texte pro Original-Segment
    # Fallback: "[Keine Ãœbersetzung]" wenn keine Ãœberlappung
```

### GUI Method-Selection
- **Dynamic Widgets**: Whisper-Model-Dropdown erscheint nur bei Whisper-Auswahl
- **Dependency-Check**: Automatische Erkennung ob Whisper/Translators verfÃ¼gbar
- **Smart State-Management**: Widget-States abhÃ¤ngig von Methoden-Auswahl

## ðŸ—ï¸ Translation Architecture (Analysis by Code-Rabbit)

**Note: Architecture analysis and sequence diagram provided by Code-Rabbit AI Code Review**

```mermaid
sequenceDiagram
    participant User
    participant GUI as VidScaler GUI
    participant Translator as translator.py
    participant SmartSRT as smart-srt-translator
    participant OpenAI as OpenAI API
    participant FFmpeg as FFmpeg

    User->>GUI: Select translation options
    GUI->>Translator: translate_srt(srt_path, source_lang, target_lang, method)
    
    alt method == "openai"
        Translator->>SmartSRT: load_env_vars()
        SmartSRT-->>Translator: Environment loaded
        Translator->>SmartSRT: OpenAITranslator()
        SmartSRT-->>Translator: Translator instance
        Translator->>SmartSRT: translate(source_lang, target_lang, srt_path)
        SmartSRT->>OpenAI: API request
        OpenAI-->>SmartSRT: Translated content
        SmartSRT-->>Translator: Translated SRT
    else method == "google"
        Translator->>Translator: _translate_via_google(srt_path, target_lang)
        Translator-->>Translator: Translated SRT
    else method == "whisper"
        Translator->>Translator: translate_via_whisper(video_path, srt_path, target_lang, model)
        Translator-->>Translator: Translated SRT
    end
    
    Translator-->>GUI: Translation complete
    GUI->>FFmpeg: Process video with translated subtitles
    FFmpeg-->>GUI: Video with subtitles ready
    GUI-->>User: Processing complete
```

This sequence diagram illustrates the translation workflow, showing how the application integrates multiple translation methods through a unified interface. The OpenAI translation path demonstrates proper provider initialization through the smart-srt-translator package, while fallback methods (Google Translate, Whisper) provide alternative translation options.